{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.load('../processed_data/complete_dataset/processed_data.pt')\n",
    "label = torch.load('../processed_data/complete_dataset/processed_label.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_toolbox.metrics import audio_dataset_split\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "X_train, y_train, X_val, y_val,\\\n",
    "X_test, y_test = audio_dataset_split(data, label, train_val_test_ratio=(0.9, 0.05, 0.05), random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flat = X_train.view(X_train.shape[0], -1)\n",
    "X_val_flat = X_val.view(X_val.shape[0], -1)\n",
    "X_test_flat = X_test.view(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=0.9)\n",
    "\n",
    "train_scaled = scaler.fit_transform(X_train_flat)\n",
    "val_scaled = scaler.transform(X_val_flat)\n",
    "test_scaled = scaler.transform(X_test_flat)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "train_data = torch.tensor(pca.fit_transform(train_scaled), dtype=torch.float, device=device)\n",
    "val_data = torch.tensor(pca.transform(val_scaled), dtype=torch.float, device=device)\n",
    "test_data = torch.tensor(pca.transform(test_scaled), dtype=torch.float, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([899, 661]), torch.Size([49, 661]), torch.Size([51, 661]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_train = torch.tensor(lb.fit_transform(y_train), device=device)\n",
    "y_val = torch.tensor(lb.fit_transform(y_val), device=device)\n",
    "y_test = torch.tensor(lb.fit_transform(y_test), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "datasets = {\n",
    "    'train': TensorDataset(train_data, y_train),\n",
    "    'val': TensorDataset(val_data, y_val),\n",
    "    'test': TensorDataset(test_data, y_test)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_toolbox.models import SimpleLinearModel\n",
    "\n",
    "input_size = train_data.size(1)\n",
    "output_size = 10\n",
    "batch_size = 32\n",
    "\n",
    "model = SimpleLinearModel(input_size, output_size, hidden_dim=64, dropout_prob=0.8, device='cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch import nn\n",
    "from audio_toolbox.models import OneHotCrossEntropyLoss\n",
    "\n",
    "loss_fn = OneHotCrossEntropyLoss()\n",
    "learning_rate = 1e-3  # Adjust the learning rate as needed\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_toolbox.trainer import ModelTrainer\n",
    "\n",
    "trainer = ModelTrainer(datasets, model, loss_fn, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config = {\n",
    "    'save': False,\n",
    "    'num_epochs': 100,\n",
    "    'batch_size': batch_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 0001, Learning rate: 0.001000, Training loss: 2.26744, Val loss: 1.82666, Test loss: 1.80099, Epoch time: 0.22367\n",
      "INFO:root:Epoch 0002, Learning rate: 0.001000, Training loss: 2.02941, Val loss: 1.03967, Test loss: 1.03557, Epoch time: 0.19351\n",
      "INFO:root:Epoch 0003, Learning rate: 0.001000, Training loss: 1.77928, Val loss: 0.54340, Test loss: 0.46794, Epoch time: 0.21136\n",
      "INFO:root:Epoch 0004, Learning rate: 0.001000, Training loss: 1.62441, Val loss: 0.26945, Test loss: 0.24986, Epoch time: 0.39459\n",
      "INFO:root:Epoch 0005, Learning rate: 0.001000, Training loss: 1.53162, Val loss: 0.17933, Test loss: 0.17954, Epoch time: 0.25400\n",
      "INFO:root:Epoch 0006, Learning rate: 0.000500, Training loss: 1.50236, Val loss: 0.15494, Test loss: 0.18007, Epoch time: 0.25394\n",
      "INFO:root:Epoch 0007, Learning rate: 0.000500, Training loss: 1.49450, Val loss: 0.13792, Test loss: 0.13796, Epoch time: 0.29746\n",
      "INFO:root:Epoch 0008, Learning rate: 0.000500, Training loss: 1.48948, Val loss: 0.12237, Test loss: 0.12247, Epoch time: 0.24196\n",
      "INFO:root:Epoch 0009, Learning rate: 0.000500, Training loss: 1.48407, Val loss: 0.11097, Test loss: 0.11089, Epoch time: 0.21682\n",
      "INFO:root:Epoch 0010, Learning rate: 0.000500, Training loss: 1.48166, Val loss: 0.10151, Test loss: 0.10147, Epoch time: 0.18768\n",
      "INFO:root:Epoch 0011, Learning rate: 0.000250, Training loss: 1.47902, Val loss: 0.09727, Test loss: 0.09726, Epoch time: 0.29683\n",
      "INFO:root:Epoch 0012, Learning rate: 0.000250, Training loss: 1.47756, Val loss: 0.09510, Test loss: 0.09508, Epoch time: 0.35110\n",
      "INFO:root:Epoch 0013, Learning rate: 0.000250, Training loss: 1.47746, Val loss: 0.09188, Test loss: 0.09198, Epoch time: 0.38053\n",
      "INFO:root:Epoch 0014, Learning rate: 0.000250, Training loss: 1.47641, Val loss: 0.08933, Test loss: 0.08931, Epoch time: 0.42353\n",
      "INFO:root:Epoch 0015, Learning rate: 0.000250, Training loss: 1.47513, Val loss: 0.08741, Test loss: 0.08743, Epoch time: 0.35528\n",
      "INFO:root:Epoch 0016, Learning rate: 0.000125, Training loss: 1.47486, Val loss: 0.08672, Test loss: 0.08669, Epoch time: 0.32649\n",
      "INFO:root:Epoch 0017, Learning rate: 0.000125, Training loss: 1.47486, Val loss: 0.08532, Test loss: 0.08534, Epoch time: 0.49243\n",
      "INFO:root:Epoch 0018, Learning rate: 0.000125, Training loss: 1.47469, Val loss: 0.08413, Test loss: 0.08406, Epoch time: 0.42170\n",
      "INFO:root:Epoch 0019, Learning rate: 0.000125, Training loss: 1.47462, Val loss: 0.08260, Test loss: 0.08264, Epoch time: 0.33494\n",
      "INFO:root:Epoch 0020, Learning rate: 0.000125, Training loss: 1.47427, Val loss: 0.07952, Test loss: 0.07952, Epoch time: 0.27798\n",
      "INFO:root:Epoch 0021, Learning rate: 0.000063, Training loss: 1.47362, Val loss: 0.07854, Test loss: 0.07857, Epoch time: 0.24466\n",
      "INFO:root:Epoch 0022, Learning rate: 0.000063, Training loss: 1.47346, Val loss: 0.07749, Test loss: 0.07749, Epoch time: 0.25107\n",
      "INFO:root:Epoch 0023, Learning rate: 0.000063, Training loss: 1.47319, Val loss: 0.07663, Test loss: 0.07660, Epoch time: 0.22985\n",
      "INFO:root:Epoch 0024, Learning rate: 0.000063, Training loss: 1.47288, Val loss: 0.07574, Test loss: 0.07574, Epoch time: 0.22679\n",
      "INFO:root:Epoch 0025, Learning rate: 0.000063, Training loss: 1.47258, Val loss: 0.07544, Test loss: 0.07544, Epoch time: 0.19526\n",
      "INFO:root:Epoch 0026, Learning rate: 0.000031, Training loss: 1.47253, Val loss: 0.07528, Test loss: 0.07530, Epoch time: 0.18890\n",
      "INFO:root:Epoch 0027, Learning rate: 0.000031, Training loss: 1.47251, Val loss: 0.07515, Test loss: 0.07514, Epoch time: 0.18791\n",
      "INFO:root:Epoch 0028, Learning rate: 0.000031, Training loss: 1.47251, Val loss: 0.07490, Test loss: 0.07493, Epoch time: 0.20110\n",
      "INFO:root:Epoch 0029, Learning rate: 0.000031, Training loss: 1.47249, Val loss: 0.07467, Test loss: 0.07468, Epoch time: 0.26700\n",
      "INFO:root:Epoch 0030, Learning rate: 0.000031, Training loss: 1.47246, Val loss: 0.07452, Test loss: 0.07446, Epoch time: 0.25555\n",
      "INFO:root:Epoch 0031, Learning rate: 0.000016, Training loss: 1.47244, Val loss: 0.16292, Test loss: 0.07434, Epoch time: 0.23935\n",
      "INFO:root:Epoch 0032, Learning rate: 0.000016, Training loss: 1.47242, Val loss: 0.07423, Test loss: 0.07421, Epoch time: 0.22874\n",
      "INFO:root:Epoch 0033, Learning rate: 0.000016, Training loss: 1.47242, Val loss: 0.07411, Test loss: 0.07409, Epoch time: 0.20168\n",
      "INFO:root:Epoch 0034, Learning rate: 0.000016, Training loss: 1.47245, Val loss: 0.07398, Test loss: 0.07398, Epoch time: 0.27798\n",
      "INFO:root:Epoch 0035, Learning rate: 0.000016, Training loss: 1.47242, Val loss: 0.07384, Test loss: 0.07385, Epoch time: 0.33015\n",
      "INFO:root:Epoch 0036, Learning rate: 0.000008, Training loss: 1.47244, Val loss: 0.07375, Test loss: 0.14236, Epoch time: 0.32812\n",
      "INFO:root:Epoch 0037, Learning rate: 0.000008, Training loss: 1.47239, Val loss: 0.07368, Test loss: 0.07370, Epoch time: 0.33295\n",
      "INFO:root:Epoch 0038, Learning rate: 0.000008, Training loss: 1.47238, Val loss: 0.07360, Test loss: 0.07357, Epoch time: 0.30164\n",
      "INFO:root:Epoch 0039, Learning rate: 0.000008, Training loss: 1.47238, Val loss: 0.07348, Test loss: 0.07352, Epoch time: 0.24350\n",
      "INFO:root:Epoch 0040, Learning rate: 0.000008, Training loss: 1.47237, Val loss: 0.07342, Test loss: 0.07341, Epoch time: 0.29499\n",
      "INFO:root:Epoch 0041, Learning rate: 0.000004, Training loss: 1.47241, Val loss: 0.07335, Test loss: 0.07333, Epoch time: 0.33413\n",
      "INFO:root:Epoch 0042, Learning rate: 0.000004, Training loss: 1.47236, Val loss: 0.07328, Test loss: 0.07333, Epoch time: 0.28791\n",
      "INFO:root:Epoch 0043, Learning rate: 0.000004, Training loss: 1.47235, Val loss: 0.07326, Test loss: 0.07323, Epoch time: 0.26171\n",
      "INFO:root:Epoch 0044, Learning rate: 0.000004, Training loss: 1.47235, Val loss: 0.07319, Test loss: 0.12072, Epoch time: 0.25540\n",
      "INFO:root:Epoch 0045, Learning rate: 0.000004, Training loss: 1.47234, Val loss: 0.07316, Test loss: 0.07310, Epoch time: 0.21989\n",
      "INFO:root:Epoch 0046, Learning rate: 0.000002, Training loss: 1.47249, Val loss: 0.07312, Test loss: 0.07308, Epoch time: 0.22217\n",
      "INFO:root:Epoch 0047, Learning rate: 0.000002, Training loss: 1.47235, Val loss: 0.07304, Test loss: 0.07305, Epoch time: 0.21023\n",
      "INFO:root:Epoch 0048, Learning rate: 0.000002, Training loss: 1.47233, Val loss: 0.07302, Test loss: 0.07301, Epoch time: 0.22083\n",
      "INFO:root:Epoch 0049, Learning rate: 0.000002, Training loss: 1.47232, Val loss: 0.07297, Test loss: 0.07297, Epoch time: 0.22082\n",
      "INFO:root:Epoch 0050, Learning rate: 0.000002, Training loss: 1.47234, Val loss: 0.07295, Test loss: 0.07297, Epoch time: 0.20211\n",
      "INFO:root:Epoch 0051, Learning rate: 0.000001, Training loss: 1.48223, Val loss: 0.07292, Test loss: 0.07294, Epoch time: 0.18334\n",
      "INFO:root:Epoch 0052, Learning rate: 0.000001, Training loss: 1.47233, Val loss: 0.07292, Test loss: 0.15760, Epoch time: 0.24181\n",
      "INFO:root:Epoch 0053, Learning rate: 0.000001, Training loss: 1.47241, Val loss: 0.07287, Test loss: 0.07289, Epoch time: 0.29602\n",
      "INFO:root:Epoch 0054, Learning rate: 0.000001, Training loss: 1.47233, Val loss: 0.07286, Test loss: 0.07288, Epoch time: 0.25775\n",
      "INFO:root:Epoch 0055, Learning rate: 0.000001, Training loss: 1.47232, Val loss: 0.07287, Test loss: 0.07286, Epoch time: 0.19611\n",
      "INFO:root:Epoch 0056, Learning rate: 0.000000, Training loss: 1.47234, Val loss: 0.07284, Test loss: 0.07293, Epoch time: 0.21489\n",
      "INFO:root:Epoch 0057, Learning rate: 0.000000, Training loss: 1.47234, Val loss: 0.07286, Test loss: 0.07286, Epoch time: 0.20289\n",
      "INFO:root:Epoch 0058, Learning rate: 0.000000, Training loss: 1.47233, Val loss: 0.07284, Test loss: 0.07286, Epoch time: 0.27331\n",
      "INFO:root:Epoch 0059, Learning rate: 0.000000, Training loss: 1.47231, Val loss: 0.07282, Test loss: 0.07284, Epoch time: 0.29010\n",
      "INFO:root:Epoch 0060, Learning rate: 0.000000, Training loss: 1.47234, Val loss: 0.07280, Test loss: 0.07279, Epoch time: 0.33193\n",
      "INFO:root:Epoch 0061, Learning rate: 0.000000, Training loss: 1.47239, Val loss: 0.07280, Test loss: 0.07280, Epoch time: 0.33885\n",
      "INFO:root:Epoch 0062, Learning rate: 0.000000, Training loss: 1.47234, Val loss: 0.07281, Test loss: 0.07278, Epoch time: 0.35075\n",
      "INFO:root:Epoch 0063, Learning rate: 0.000000, Training loss: 1.47237, Val loss: 0.07281, Test loss: 0.07279, Epoch time: 0.27653\n",
      "INFO:root:Epoch 0064, Learning rate: 0.000000, Training loss: 1.47245, Val loss: 0.07281, Test loss: 0.07278, Epoch time: 0.44508\n",
      "INFO:root:Epoch 0065, Learning rate: 0.000000, Training loss: 1.47235, Val loss: 0.07277, Test loss: 0.07282, Epoch time: 0.32529\n",
      "INFO:root:Epoch 0066, Learning rate: 0.000000, Training loss: 1.47232, Val loss: 0.07276, Test loss: 0.07275, Epoch time: 0.26424\n",
      "INFO:root:Epoch 0067, Learning rate: 0.000000, Training loss: 1.47233, Val loss: 0.07274, Test loss: 0.07278, Epoch time: 0.33795\n",
      "INFO:root:Epoch 0068, Learning rate: 0.000000, Training loss: 1.47232, Val loss: 0.07276, Test loss: 0.07277, Epoch time: 0.36370\n",
      "INFO:root:Epoch 0069, Learning rate: 0.000000, Training loss: 1.47232, Val loss: 0.07278, Test loss: 0.07275, Epoch time: 0.32060\n",
      "INFO:root:Epoch 0070, Learning rate: 0.000000, Training loss: 1.47233, Val loss: 0.07275, Test loss: 0.07275, Epoch time: 0.28228\n",
      "INFO:root:Epoch 0071, Learning rate: 0.000000, Training loss: 1.47234, Val loss: 0.07276, Test loss: 0.07283, Epoch time: 0.22926\n",
      "INFO:root:Epoch 0072, Learning rate: 0.000000, Training loss: 1.47232, Val loss: 0.07275, Test loss: 0.07278, Epoch time: 0.27235\n",
      "INFO:root:Epoch 0073, Learning rate: 0.000000, Training loss: 1.47237, Val loss: 0.07276, Test loss: 0.07276, Epoch time: 0.22919\n",
      "INFO:root:Epoch 0074, Learning rate: 0.000000, Training loss: 1.48213, Val loss: 0.07274, Test loss: 0.07274, Epoch time: 0.27512\n",
      "INFO:root:Epoch 0075, Learning rate: 0.000000, Training loss: 1.47234, Val loss: 0.07274, Test loss: 0.07275, Epoch time: 0.27684\n",
      "INFO:root:Epoch 0076, Learning rate: 0.000000, Training loss: 1.47230, Val loss: 0.07276, Test loss: 0.07279, Epoch time: 0.23577\n",
      "INFO:root:Epoch 0077, Learning rate: 0.000000, Training loss: 1.47231, Val loss: 0.07273, Test loss: 0.07275, Epoch time: 0.22702\n",
      "INFO:root:Epoch 0078, Learning rate: 0.000000, Training loss: 1.47230, Val loss: 0.07274, Test loss: 0.07273, Epoch time: 0.21107\n",
      "INFO:root:Epoch 0079, Learning rate: 0.000000, Training loss: 1.47238, Val loss: 0.07273, Test loss: 0.07275, Epoch time: 0.26634\n",
      "INFO:root:Epoch 0080, Learning rate: 0.000000, Training loss: 1.47231, Val loss: 0.07274, Test loss: 0.07283, Epoch time: 0.45771\n",
      "INFO:root:Epoch 0081, Learning rate: 0.000000, Training loss: 1.47233, Val loss: 0.07274, Test loss: 0.07276, Epoch time: 0.36625\n",
      "INFO:root:Epoch 0082, Learning rate: 0.000000, Training loss: 1.47231, Val loss: 0.07274, Test loss: 0.07275, Epoch time: 0.32216\n",
      "INFO:root:Epoch 0083, Learning rate: 0.000000, Training loss: 1.47232, Val loss: 0.07275, Test loss: 0.12478, Epoch time: 0.29997\n",
      "INFO:root:Epoch 0084, Learning rate: 0.000000, Training loss: 1.48212, Val loss: 0.07273, Test loss: 0.07281, Epoch time: 0.25609\n",
      "INFO:root:Epoch 0085, Learning rate: 0.000000, Training loss: 1.47233, Val loss: 0.07274, Test loss: 0.07277, Epoch time: 0.26130\n",
      "INFO:root:Epoch 0086, Learning rate: 0.000000, Training loss: 1.47236, Val loss: 0.07274, Test loss: 0.07273, Epoch time: 0.24559\n",
      "INFO:root:Epoch 0087, Learning rate: 0.000000, Training loss: 1.47231, Val loss: 0.07275, Test loss: 0.07273, Epoch time: 0.25553\n",
      "INFO:root:Epoch 0088, Learning rate: 0.000000, Training loss: 1.48224, Val loss: 0.07273, Test loss: 0.07277, Epoch time: 0.24250\n",
      "INFO:root:Epoch 0089, Learning rate: 0.000000, Training loss: 1.47231, Val loss: 0.07275, Test loss: 0.07274, Epoch time: 0.22719\n",
      "INFO:root:Epoch 0090, Learning rate: 0.000000, Training loss: 1.47232, Val loss: 0.07273, Test loss: 0.07276, Epoch time: 0.22661\n",
      "INFO:root:Epoch 0091, Learning rate: 0.000000, Training loss: 1.47237, Val loss: 0.07274, Test loss: 0.07276, Epoch time: 0.20927\n",
      "INFO:root:Epoch 0092, Learning rate: 0.000000, Training loss: 1.47233, Val loss: 0.07287, Test loss: 0.07273, Epoch time: 0.20065\n",
      "INFO:root:Epoch 0093, Learning rate: 0.000000, Training loss: 1.47235, Val loss: 0.07275, Test loss: 0.07273, Epoch time: 0.19784\n",
      "INFO:root:Epoch 0094, Learning rate: 0.000000, Training loss: 1.48218, Val loss: 0.07273, Test loss: 0.07275, Epoch time: 0.22064\n",
      "INFO:root:Epoch 0095, Learning rate: 0.000000, Training loss: 1.47232, Val loss: 0.07274, Test loss: 0.07278, Epoch time: 0.26912\n",
      "INFO:root:Epoch 0096, Learning rate: 0.000000, Training loss: 1.47237, Val loss: 0.07274, Test loss: 0.07273, Epoch time: 0.22331\n",
      "INFO:root:Epoch 0097, Learning rate: 0.000000, Training loss: 1.47234, Val loss: 0.07274, Test loss: 0.07280, Epoch time: 0.21785\n",
      "INFO:root:Epoch 0098, Learning rate: 0.000000, Training loss: 1.47233, Val loss: 0.07277, Test loss: 0.07272, Epoch time: 0.22684\n",
      "INFO:root:Epoch 0099, Learning rate: 0.000000, Training loss: 1.47231, Val loss: 0.07274, Test loss: 0.07276, Epoch time: 0.19590\n",
      "INFO:root:Epoch 0100, Learning rate: 0.000000, Training loss: 1.47233, Val loss: 0.07274, Test loss: 0.07275, Epoch time: 0.22604\n",
      "INFO:root:Best model at epoch 0084 with validation loss 0.07273\n"
     ]
    }
   ],
   "source": [
    "trainer.train(**trainer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res = trainer.predict(train_data)\n",
    "val_res = trainer.predict(val_data)\n",
    "test_res = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 98.89%\n",
      "Validation accuracy: 40.82%\n",
      "Test accuracy: 52.94%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f\"Train accuracy: {100 * accuracy_score(train_res, y_train):.2f}%\")\n",
    "print(f\"Validation accuracy: {100 * accuracy_score(val_res, y_val):.2f}%\")\n",
    "print(f\"Test accuracy: {100 * accuracy_score(test_res, y_test):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_toolbox.metrics import precision_recall\n",
    "\n",
    "_, _, _, f1_train = precision_recall(trainer, train_data, y_train)\n",
    "_, _, _, f1_val = precision_recall(trainer, val_data, y_val)\n",
    "_, _, _, f1_test = precision_recall(trainer, test_data, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1 score: 0.9978\n",
      "Validation f1 score: 0.4342\n",
      "Test f1 score: 0.4468\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train f1 score: {f1_train:.4f}\")\n",
    "print(f\"Validation f1 score: {f1_val:.4f}\")\n",
    "print(f\"Test f1 score: {f1_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
