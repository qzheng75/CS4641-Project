{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.350088</td>\n",
       "      <td>0.088757</td>\n",
       "      <td>0.130228</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>1784.165850</td>\n",
       "      <td>129774.064525</td>\n",
       "      <td>2002.449060</td>\n",
       "      <td>85882.761315</td>\n",
       "      <td>...</td>\n",
       "      <td>52.420910</td>\n",
       "      <td>-1.690215</td>\n",
       "      <td>36.524071</td>\n",
       "      <td>-0.408979</td>\n",
       "      <td>41.597103</td>\n",
       "      <td>-2.303523</td>\n",
       "      <td>55.062923</td>\n",
       "      <td>1.221291</td>\n",
       "      <td>46.936035</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00001.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.340914</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.095948</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>1530.176679</td>\n",
       "      <td>375850.073649</td>\n",
       "      <td>2039.036516</td>\n",
       "      <td>213843.755497</td>\n",
       "      <td>...</td>\n",
       "      <td>55.356403</td>\n",
       "      <td>-0.731125</td>\n",
       "      <td>60.314529</td>\n",
       "      <td>0.295073</td>\n",
       "      <td>48.120598</td>\n",
       "      <td>-0.283518</td>\n",
       "      <td>51.106190</td>\n",
       "      <td>0.531217</td>\n",
       "      <td>45.786282</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00002.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.363637</td>\n",
       "      <td>0.085275</td>\n",
       "      <td>0.175570</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>1552.811865</td>\n",
       "      <td>156467.643368</td>\n",
       "      <td>1747.702312</td>\n",
       "      <td>76254.192257</td>\n",
       "      <td>...</td>\n",
       "      <td>40.598766</td>\n",
       "      <td>-7.729093</td>\n",
       "      <td>47.639427</td>\n",
       "      <td>-1.816407</td>\n",
       "      <td>52.382141</td>\n",
       "      <td>-3.439720</td>\n",
       "      <td>46.639660</td>\n",
       "      <td>-2.231258</td>\n",
       "      <td>30.573025</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.093999</td>\n",
       "      <td>0.141093</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>1070.106615</td>\n",
       "      <td>184355.942417</td>\n",
       "      <td>1596.412872</td>\n",
       "      <td>166441.494769</td>\n",
       "      <td>...</td>\n",
       "      <td>44.427753</td>\n",
       "      <td>-3.319597</td>\n",
       "      <td>50.206673</td>\n",
       "      <td>0.636965</td>\n",
       "      <td>37.319130</td>\n",
       "      <td>-0.619121</td>\n",
       "      <td>37.259739</td>\n",
       "      <td>-3.407448</td>\n",
       "      <td>31.949339</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00004.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.308526</td>\n",
       "      <td>0.087841</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>1835.004266</td>\n",
       "      <td>343399.939274</td>\n",
       "      <td>1748.172116</td>\n",
       "      <td>88445.209036</td>\n",
       "      <td>...</td>\n",
       "      <td>86.099236</td>\n",
       "      <td>-5.454034</td>\n",
       "      <td>75.269707</td>\n",
       "      <td>-0.916874</td>\n",
       "      <td>53.613918</td>\n",
       "      <td>-4.404827</td>\n",
       "      <td>62.910812</td>\n",
       "      <td>-11.703234</td>\n",
       "      <td>55.195160</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
       "0  blues.00000.wav  661794          0.350088         0.088757  0.130228   \n",
       "1  blues.00001.wav  661794          0.340914         0.094980  0.095948   \n",
       "2  blues.00002.wav  661794          0.363637         0.085275  0.175570   \n",
       "3  blues.00003.wav  661794          0.404785         0.093999  0.141093   \n",
       "4  blues.00004.wav  661794          0.308526         0.087841  0.091529   \n",
       "\n",
       "    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
       "0  0.002827             1784.165850          129774.064525   \n",
       "1  0.002373             1530.176679          375850.073649   \n",
       "2  0.002746             1552.811865          156467.643368   \n",
       "3  0.006346             1070.106615          184355.942417   \n",
       "4  0.002303             1835.004266          343399.939274   \n",
       "\n",
       "   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
       "0              2002.449060            85882.761315  ...   52.420910   \n",
       "1              2039.036516           213843.755497  ...   55.356403   \n",
       "2              1747.702312            76254.192257  ...   40.598766   \n",
       "3              1596.412872           166441.494769  ...   44.427753   \n",
       "4              1748.172116            88445.209036  ...   86.099236   \n",
       "\n",
       "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n",
       "0    -1.690215   36.524071    -0.408979   41.597103    -2.303523   55.062923   \n",
       "1    -0.731125   60.314529     0.295073   48.120598    -0.283518   51.106190   \n",
       "2    -7.729093   47.639427    -1.816407   52.382141    -3.439720   46.639660   \n",
       "3    -3.319597   50.206673     0.636965   37.319130    -0.619121   37.259739   \n",
       "4    -5.454034   75.269707    -0.916874   53.613918    -4.404827   62.910812   \n",
       "\n",
       "   mfcc20_mean  mfcc20_var  label  \n",
       "0     1.221291   46.936035  blues  \n",
       "1     0.531217   45.786282  blues  \n",
       "2    -2.231258   30.573025  blues  \n",
       "3    -3.407448   31.949339  blues  \n",
       "4   -11.703234   55.195160  blues  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "audio_root_folder = './archive/data'\n",
    "labels_csv = os.path.join(audio_root_folder, 'features_30_sec.csv')\n",
    "df = pd.read_csv(labels_csv, header=0)\n",
    "df.drop(df.loc[df.filename == 'jazz.00054.wav'].index, inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "RANDOM_SEED = RANDOM_STATE = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.random.manual_seed(RANDOM_SEED);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "filenames = df['filename']\n",
    "labels = df['label']\n",
    "\n",
    "files_train, files_val_test, labels_train, labels_val_test = train_test_split(\n",
    "    filenames, labels, test_size=0.1, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "files_val, files_test, labels_val, labels_test = train_test_split(\n",
    "    files_val_test, labels_val_test, test_size=0.5, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading audios for Training set: 100%|██████████| 899/899 [00:05<00:00, 159.75it/s]\n",
      "Processing for Training set: 100%|██████████| 899/899 [01:15<00:00, 11.95it/s]\n",
      "Loading audios for Validation set: 100%|██████████| 50/50 [00:00<00:00, 280.82it/s]\n",
      "Processing for Validation set: 100%|██████████| 50/50 [00:03<00:00, 12.72it/s]\n",
      "Loading audios for Testing set: 100%|██████████| 50/50 [00:00<00:00, 231.48it/s]\n",
      "Processing for Testing set: 100%|██████████| 50/50 [00:03<00:00, 13.92it/s]\n"
     ]
    }
   ],
   "source": [
    "from audio_toolbox.dataset import AudioOTFDataset\n",
    "\n",
    "num_frames = 1290\n",
    "label_encoding = 'Label'\n",
    "scaling_strategy = None\n",
    "\n",
    "datasets = {\n",
    "    'train':\n",
    "        AudioOTFDataset(\n",
    "            root_folder=audio_root_folder,\n",
    "            filenames=files_train.tolist(),\n",
    "            labels=labels_train.tolist(),\n",
    "            num_frames=num_frames,\n",
    "            scaling_strategy=scaling_strategy,\n",
    "            name='Training set',\n",
    "            label_encoding=label_encoding,\n",
    "            flatten_features=True,\n",
    "            shuffle=True,\n",
    "            random_state=RANDOM_STATE\n",
    "        ),\n",
    "    'val':\n",
    "        AudioOTFDataset(\n",
    "            root_folder=audio_root_folder,\n",
    "            filenames=files_val.tolist(),\n",
    "            labels=labels_val.tolist(),\n",
    "            num_frames=num_frames,\n",
    "            scaling_strategy=scaling_strategy,\n",
    "            name='Validation set',\n",
    "            label_encoding=label_encoding,\n",
    "            flatten_features=True,\n",
    "            shuffle=True,\n",
    "            random_state=RANDOM_STATE\n",
    "        ),\n",
    "    'test':\n",
    "        AudioOTFDataset(\n",
    "            root_folder=audio_root_folder,\n",
    "            filenames=files_test.tolist(),\n",
    "            labels=labels_test.tolist(),\n",
    "            num_frames=num_frames,\n",
    "            scaling_strategy=scaling_strategy,\n",
    "            name='Testing set',\n",
    "            label_encoding=label_encoding,\n",
    "            flatten_features=True,\n",
    "            shuffle=True,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(899, 50, 50)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train, n_val, n_test = len(datasets['train']), len(datasets['val']), len(datasets['test'])\n",
    "n_train, n_val, n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Training set ======\n",
      "Root folder: ./archive/data\n",
      "Number of samples: 899\n",
      "Shape of one sample: torch.Size([92880])\n",
      "Number of classes: 10\n",
      "Features:\n",
      "\tn_mfcc: 12\n",
      "\tn_chroma: 12\n",
      "\tn_derivatives: 2\n",
      "Scaling strategy: None\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "print(repr(datasets['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data saved\n",
      "Train label saved\n",
      "Val data saved\n",
      "Val label saved\n",
      "Test data saved\n",
      "Test label saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Save the processed tensors to save time next time\n",
    "os.makedirs('./processed_data/dl_data/mlp_data/full_data', exist_ok=True)\n",
    "torch.save(datasets['train'].X, 'processed_data/dl_data/mlp_data/full_data/dl_modeling_train_data.pt')\n",
    "print('Train data saved')\n",
    "torch.save(datasets['train'].labels, 'processed_data/dl_data/mlp_data/full_data/dl_modeling_train_label.pt')\n",
    "print('Train label saved')\n",
    "torch.save(datasets['val'].X, 'processed_data/dl_data/mlp_data/full_data/dl_modeling_val_data.pt')\n",
    "print('Val data saved')\n",
    "torch.save(datasets['val'].labels, 'processed_data/dl_data/mlp_data/full_data/dl_modeling_val_label.pt')\n",
    "print('Val label saved')\n",
    "torch.save(datasets['test'].X, 'processed_data/dl_data/mlp_data/full_data/dl_modeling_test_data.pt')\n",
    "print('Test data saved')\n",
    "torch.save(datasets['test'].labels, 'processed_data/dl_data/mlp_data/full_data/dl_modeling_test_label.pt')\n",
    "print('Test label saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=0.95)\n",
    "\n",
    "train_scaled = scaler.fit_transform(datasets['train'].X)\n",
    "val_scaled = scaler.transform(datasets['val'].X)\n",
    "test_scaled = scaler.transform(datasets['test'].X)\n",
    "\n",
    "train_data = torch.tensor(pca.fit_transform(train_scaled), dtype=torch.float)\n",
    "val_data = torch.tensor(pca.transform(val_scaled), dtype=torch.float)\n",
    "test_data = torch.tensor(pca.transform(test_scaled), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([899, 753]), torch.Size([50, 753]), torch.Size([50, 753]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, val_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data saved\n",
      "Train label saved\n",
      "Val data saved\n",
      "Val label saved\n",
      "Test data saved\n",
      "Test label saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Save the processed tensors to save time next time\n",
    "os.makedirs('./processed_data/dl_data/mlp_data/pca_data', exist_ok=True)\n",
    "torch.save(train_data, 'processed_data/dl_data/mlp_data/pca_data/dl_modeling_train_data.pt')\n",
    "print('Train data saved')\n",
    "torch.save(datasets['train'].labels, 'processed_data/dl_data/mlp_data/pca_data/dl_modeling_train_label.pt')\n",
    "print('Train label saved')\n",
    "torch.save(val_data, 'processed_data/dl_data/mlp_data/pca_data/dl_modeling_val_data.pt')\n",
    "print('Val data saved')\n",
    "torch.save(datasets['val'].labels, 'processed_data/dl_data/mlp_data/pca_data/dl_modeling_val_label.pt')\n",
    "print('Val label saved')\n",
    "torch.save(test_data, 'processed_data/dl_data/mlp_data/pca_data/dl_modeling_test_data.pt')\n",
    "print('Test data saved')\n",
    "torch.save(datasets['test'].labels, 'processed_data/dl_data/mlp_data/pca_data/dl_modeling_test_label.pt')\n",
    "print('Test label saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([899, 753]),\n",
       " torch.Size([899]),\n",
       " torch.Size([50, 753]),\n",
       " torch.Size([50]),\n",
       " torch.Size([50, 753]),\n",
       " torch.Size([50]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "train_data = torch.load('processed_data/dl_data/mlp_data/pca_data/dl_modeling_train_data.pt')\n",
    "val_data = torch.load('processed_data/dl_data/mlp_data/pca_data/dl_modeling_val_data.pt')\n",
    "test_data = torch.load('processed_data/dl_data/mlp_data/pca_data/dl_modeling_test_data.pt')\n",
    "\n",
    "train_label = torch.load('processed_data/dl_data/mlp_data/pca_data/dl_modeling_train_label.pt')\n",
    "val_label = torch.load('processed_data/dl_data/mlp_data/pca_data/dl_modeling_val_label.pt')\n",
    "test_label = torch.load('processed_data/dl_data/mlp_data/pca_data/dl_modeling_test_label.pt')\n",
    "\n",
    "train_data.shape, train_label.shape, val_data.shape, val_label.shape, test_data.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([899, 753])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "datasets = {\n",
    "    'train': TensorDataset(train_data, train_label),\n",
    "    'val': TensorDataset(val_data, val_label),\n",
    "    'test': TensorDataset(test_data, test_label)\n",
    "}\n",
    "\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_toolbox.models import SimpleLinearModel\n",
    "\n",
    "input_size = train_data.size(1)\n",
    "output_size = 10\n",
    "batch_size = 16\n",
    "\n",
    "model = SimpleLinearModel(input_size, output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch import nn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3  # Adjust the learning rate as needed\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_toolbox.trainer import ModelTrainer\n",
    "\n",
    "trainer = ModelTrainer(datasets, model, loss_fn, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config = {\n",
    "    'save': False,\n",
    "    'num_epochs': 100,\n",
    "    'batch_size': batch_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 0001, Learning rate: 0.001000, Training loss: 2.28126, Val loss: 1.78656, Test loss: 1.71039, Epoch time: 0.15499\n",
      "INFO:root:Epoch 0002, Learning rate: 0.001000, Training loss: 2.00162, Val loss: 0.82671, Test loss: 0.81932, Epoch time: 0.14773\n",
      "INFO:root:Epoch 0003, Learning rate: 0.001000, Training loss: 1.71117, Val loss: 0.27308, Test loss: 0.27406, Epoch time: 0.13926\n",
      "INFO:root:Epoch 0004, Learning rate: 0.001000, Training loss: 1.54487, Val loss: 0.14602, Test loss: 0.14601, Epoch time: 0.14612\n",
      "INFO:root:Epoch 0005, Learning rate: 0.001000, Training loss: 1.50000, Val loss: 0.09011, Test loss: 0.08938, Epoch time: 0.16338\n",
      "INFO:root:Epoch 0006, Learning rate: 0.000500, Training loss: 1.48213, Val loss: 0.09386, Test loss: 0.07523, Epoch time: 0.16763\n",
      "INFO:root:Epoch 0007, Learning rate: 0.000500, Training loss: 1.47711, Val loss: 0.06532, Test loss: 0.06534, Epoch time: 0.15579\n",
      "INFO:root:Epoch 0008, Learning rate: 0.000500, Training loss: 1.47446, Val loss: 0.05544, Test loss: 0.05540, Epoch time: 0.14648\n",
      "INFO:root:Epoch 0009, Learning rate: 0.000500, Training loss: 1.47104, Val loss: 0.05253, Test loss: 0.05255, Epoch time: 0.14776\n",
      "INFO:root:Epoch 0010, Learning rate: 0.000500, Training loss: 1.47006, Val loss: 0.04899, Test loss: 0.04907, Epoch time: 0.18224\n",
      "INFO:root:Epoch 0011, Learning rate: 0.000250, Training loss: 1.46926, Val loss: 0.04607, Test loss: 0.04606, Epoch time: 0.15606\n",
      "INFO:root:Epoch 0012, Learning rate: 0.000250, Training loss: 1.46829, Val loss: 0.04450, Test loss: 0.04444, Epoch time: 0.15023\n",
      "INFO:root:Epoch 0013, Learning rate: 0.000250, Training loss: 1.46754, Val loss: 0.04420, Test loss: 0.04421, Epoch time: 0.13811\n",
      "INFO:root:Epoch 0014, Learning rate: 0.000250, Training loss: 1.46741, Val loss: 0.04407, Test loss: 0.04402, Epoch time: 0.14839\n",
      "INFO:root:Epoch 0015, Learning rate: 0.000250, Training loss: 1.46732, Val loss: 0.04392, Test loss: 0.04389, Epoch time: 0.15646\n",
      "INFO:root:Epoch 0016, Learning rate: 0.000125, Training loss: 1.46727, Val loss: 0.04385, Test loss: 0.04386, Epoch time: 0.12752\n",
      "INFO:root:Epoch 0017, Learning rate: 0.000125, Training loss: 1.46721, Val loss: 0.04374, Test loss: 0.04367, Epoch time: 0.12781\n",
      "INFO:root:Epoch 0018, Learning rate: 0.000125, Training loss: 1.46717, Val loss: 0.04359, Test loss: 0.04358, Epoch time: 0.12730\n",
      "INFO:root:Epoch 0019, Learning rate: 0.000125, Training loss: 1.46719, Val loss: 0.04349, Test loss: 0.04351, Epoch time: 0.12877\n",
      "INFO:root:Epoch 0020, Learning rate: 0.000125, Training loss: 1.46711, Val loss: 0.04332, Test loss: 0.04334, Epoch time: 0.13358\n",
      "INFO:root:Epoch 0021, Learning rate: 0.000063, Training loss: 1.46709, Val loss: 0.04325, Test loss: 0.04324, Epoch time: 0.12983\n",
      "INFO:root:Epoch 0022, Learning rate: 0.000063, Training loss: 1.46709, Val loss: 0.04314, Test loss: 0.04317, Epoch time: 0.12899\n",
      "INFO:root:Epoch 0023, Learning rate: 0.000063, Training loss: 1.46708, Val loss: 0.04303, Test loss: 0.04302, Epoch time: 0.12781\n",
      "INFO:root:Epoch 0024, Learning rate: 0.000063, Training loss: 1.46704, Val loss: 0.04293, Test loss: 0.04299, Epoch time: 0.12978\n",
      "INFO:root:Epoch 0025, Learning rate: 0.000063, Training loss: 1.46704, Val loss: 0.04284, Test loss: 0.04284, Epoch time: 0.16022\n",
      "INFO:root:Epoch 0026, Learning rate: 0.000031, Training loss: 1.46702, Val loss: 0.04285, Test loss: 0.04278, Epoch time: 0.13412\n",
      "INFO:root:Epoch 0027, Learning rate: 0.000031, Training loss: 1.46702, Val loss: 0.04271, Test loss: 0.04271, Epoch time: 0.13403\n",
      "INFO:root:Epoch 0028, Learning rate: 0.000031, Training loss: 1.46701, Val loss: 0.04261, Test loss: 0.04261, Epoch time: 0.13821\n",
      "INFO:root:Epoch 0029, Learning rate: 0.000031, Training loss: 1.46700, Val loss: 0.04253, Test loss: 0.04254, Epoch time: 0.14582\n",
      "INFO:root:Epoch 0030, Learning rate: 0.000031, Training loss: 1.46699, Val loss: 0.04249, Test loss: 0.04248, Epoch time: 0.21287\n",
      "INFO:root:Epoch 0031, Learning rate: 0.000016, Training loss: 1.46700, Val loss: 0.04243, Test loss: 0.04247, Epoch time: 0.24633\n",
      "INFO:root:Epoch 0032, Learning rate: 0.000016, Training loss: 1.46698, Val loss: 0.04240, Test loss: 0.04239, Epoch time: 0.23273\n",
      "INFO:root:Epoch 0033, Learning rate: 0.000016, Training loss: 1.46700, Val loss: 0.04232, Test loss: 0.04232, Epoch time: 0.27632\n",
      "INFO:root:Epoch 0034, Learning rate: 0.000016, Training loss: 1.46700, Val loss: 0.04236, Test loss: 0.04227, Epoch time: 0.29070\n",
      "INFO:root:Epoch 0035, Learning rate: 0.000016, Training loss: 1.46699, Val loss: 0.04222, Test loss: 0.04223, Epoch time: 0.26685\n",
      "INFO:root:Epoch 0036, Learning rate: 0.000008, Training loss: 1.46700, Val loss: 0.04230, Test loss: 0.04225, Epoch time: 0.29975\n",
      "INFO:root:Epoch 0037, Learning rate: 0.000008, Training loss: 1.46697, Val loss: 0.04219, Test loss: 0.04217, Epoch time: 0.30121\n",
      "INFO:root:Epoch 0038, Learning rate: 0.000008, Training loss: 1.46696, Val loss: 0.04215, Test loss: 0.04215, Epoch time: 0.46204\n",
      "INFO:root:Epoch 0039, Learning rate: 0.000008, Training loss: 1.46704, Val loss: 0.04210, Test loss: 0.04212, Epoch time: 0.36571\n",
      "INFO:root:Epoch 0040, Learning rate: 0.000008, Training loss: 1.46696, Val loss: 0.04207, Test loss: 0.04208, Epoch time: 0.28480\n",
      "INFO:root:Epoch 0041, Learning rate: 0.000004, Training loss: 1.46695, Val loss: 0.04207, Test loss: 0.04204, Epoch time: 0.17824\n",
      "INFO:root:Epoch 0042, Learning rate: 0.000004, Training loss: 1.46695, Val loss: 0.04206, Test loss: 0.04205, Epoch time: 0.15852\n",
      "INFO:root:Epoch 0043, Learning rate: 0.000004, Training loss: 1.46695, Val loss: 0.04202, Test loss: 0.04202, Epoch time: 0.13997\n",
      "INFO:root:Epoch 0044, Learning rate: 0.000004, Training loss: 1.46695, Val loss: 0.04200, Test loss: 0.04203, Epoch time: 0.14053\n",
      "INFO:root:Epoch 0045, Learning rate: 0.000004, Training loss: 1.46697, Val loss: 0.04198, Test loss: 0.04199, Epoch time: 0.19173\n",
      "INFO:root:Epoch 0046, Learning rate: 0.000002, Training loss: 1.46694, Val loss: 0.12705, Test loss: 0.04200, Epoch time: 0.16299\n",
      "INFO:root:Epoch 0047, Learning rate: 0.000002, Training loss: 1.46700, Val loss: 0.04203, Test loss: 0.04196, Epoch time: 0.13856\n",
      "INFO:root:Epoch 0048, Learning rate: 0.000002, Training loss: 1.46695, Val loss: 0.04194, Test loss: 0.04196, Epoch time: 0.14192\n",
      "INFO:root:Epoch 0049, Learning rate: 0.000002, Training loss: 1.46695, Val loss: 0.04196, Test loss: 0.15643, Epoch time: 0.13430\n",
      "INFO:root:Epoch 0050, Learning rate: 0.000002, Training loss: 1.46699, Val loss: 0.04193, Test loss: 0.04193, Epoch time: 0.13057\n",
      "INFO:root:Epoch 0051, Learning rate: 0.000001, Training loss: 1.46695, Val loss: 0.04194, Test loss: 0.04192, Epoch time: 0.14643\n",
      "INFO:root:Epoch 0052, Learning rate: 0.000001, Training loss: 1.46695, Val loss: 0.04192, Test loss: 0.04191, Epoch time: 0.16227\n",
      "INFO:root:Epoch 0053, Learning rate: 0.000001, Training loss: 1.46695, Val loss: 0.04192, Test loss: 0.04194, Epoch time: 0.14667\n",
      "INFO:root:Epoch 0054, Learning rate: 0.000001, Training loss: 1.46695, Val loss: 0.04193, Test loss: 0.04190, Epoch time: 0.15846\n",
      "INFO:root:Epoch 0055, Learning rate: 0.000001, Training loss: 1.46694, Val loss: 0.04192, Test loss: 0.04190, Epoch time: 0.14529\n",
      "INFO:root:Epoch 0056, Learning rate: 0.000000, Training loss: 1.46695, Val loss: 0.04189, Test loss: 0.04190, Epoch time: 0.13462\n",
      "INFO:root:Epoch 0057, Learning rate: 0.000000, Training loss: 1.46694, Val loss: 0.04189, Test loss: 0.04189, Epoch time: 0.13578\n",
      "INFO:root:Epoch 0058, Learning rate: 0.000000, Training loss: 1.46696, Val loss: 0.04189, Test loss: 0.04190, Epoch time: 0.14792\n",
      "INFO:root:Epoch 0059, Learning rate: 0.000000, Training loss: 1.46694, Val loss: 0.04194, Test loss: 0.04189, Epoch time: 0.15092\n",
      "INFO:root:Epoch 0060, Learning rate: 0.000000, Training loss: 1.46695, Val loss: 0.04189, Test loss: 0.04190, Epoch time: 0.16784\n",
      "INFO:root:Epoch 0061, Learning rate: 0.000000, Training loss: 1.46695, Val loss: 0.04194, Test loss: 0.04191, Epoch time: 0.13914\n",
      "INFO:root:Epoch 0062, Learning rate: 0.000000, Training loss: 1.46695, Val loss: 0.04188, Test loss: 0.04187, Epoch time: 0.14807\n",
      "INFO:root:Epoch 0063, Learning rate: 0.000000, Training loss: 1.46696, Val loss: 0.04188, Test loss: 0.04188, Epoch time: 0.14198\n",
      "INFO:root:Epoch 0064, Learning rate: 0.000000, Training loss: 1.46697, Val loss: 0.04188, Test loss: 0.04188, Epoch time: 0.15113\n",
      "INFO:root:Epoch 0065, Learning rate: 0.000000, Training loss: 1.46696, Val loss: 0.04192, Test loss: 0.04187, Epoch time: 0.14356\n",
      "INFO:root:Epoch 0066, Learning rate: 0.000000, Training loss: 1.46694, Val loss: 0.04187, Test loss: 0.04194, Epoch time: 0.13775\n",
      "INFO:root:Epoch 0067, Learning rate: 0.000000, Training loss: 1.46695, Val loss: 0.04191, Test loss: 0.04186, Epoch time: 0.15406\n",
      "INFO:root:Epoch 0068, Learning rate: 0.000000, Training loss: 1.46695, Val loss: 0.04190, Test loss: 0.04187, Epoch time: 0.12625\n",
      "INFO:root:Epoch 0069, Learning rate: 0.000000, Training loss: 1.46697, Val loss: 0.04188, Test loss: 0.04187, Epoch time: 0.12856\n",
      "INFO:root:Epoch 0070, Learning rate: 0.000000, Training loss: 1.46694, Val loss: 0.04188, Test loss: 0.04188, Epoch time: 0.12837\n",
      "INFO:root:Epoch 0071, Learning rate: 0.000000, Training loss: 1.46703, Val loss: 0.04186, Test loss: 0.04190, Epoch time: 0.13086\n",
      "INFO:root:Epoch 0072, Learning rate: 0.000000, Training loss: 1.46695, Val loss: 0.04187, Test loss: 0.04186, Epoch time: 0.12799\n",
      "INFO:root:Epoch 0073, Learning rate: 0.000000, Training loss: 1.46694, Val loss: 0.04187, Test loss: 0.04187, Epoch time: 0.13341\n",
      "INFO:root:Epoch 0074, Learning rate: 0.000000, Training loss: 1.46698, Val loss: 0.04188, Test loss: 0.04192, Epoch time: 0.15099\n",
      "INFO:root:Epoch 0075, Learning rate: 0.000000, Training loss: 1.46695, Val loss: 0.04186, Test loss: 0.04187, Epoch time: 0.14195\n",
      "INFO:root:Epoch 0076, Learning rate: 0.000000, Training loss: 1.46694, Val loss: 0.04186, Test loss: 0.04188, Epoch time: 0.13819\n",
      "INFO:root:Epoch 0077, Learning rate: 0.000000, Training loss: 1.46694, Val loss: 0.04188, Test loss: 0.04188, Epoch time: 0.13708\n",
      "INFO:root:Epoch 0078, Learning rate: 0.000000, Training loss: 1.46695, Val loss: 0.04186, Test loss: 0.04189, Epoch time: 0.13335\n",
      "INFO:root:Epoch 0079, Learning rate: 0.000000, Training loss: 1.46694, Val loss: 0.04186, Test loss: 0.04189, Epoch time: 0.13384\n",
      "INFO:root:Epoch 0080, Learning rate: 0.000000, Training loss: 1.46696, Val loss: 0.04187, Test loss: 0.04187, Epoch time: 0.16181\n",
      "INFO:root:Epoch 0081, Learning rate: 0.000000, Training loss: 1.46695, Val loss: 0.04188, Test loss: 0.04185, Epoch time: 0.14587\n",
      "INFO:root:Epoch 0082, Learning rate: 0.000000, Training loss: 1.46696, Val loss: 0.04187, Test loss: 0.04186, Epoch time: 0.14615\n",
      "INFO:root:Epoch 0083, Learning rate: 0.000000, Training loss: 1.46694, Val loss: 0.04187, Test loss: 0.04186, Epoch time: 0.13675\n",
      "INFO:root:Epoch 0084, Learning rate: 0.000000, Training loss: 1.46695, Val loss: 0.04190, Test loss: 0.04186, Epoch time: 0.14118\n",
      "INFO:root:Epoch 0085, Learning rate: 0.000000, Training loss: 1.46695, Val loss: 0.04189, Test loss: 0.04188, Epoch time: 0.14163\n",
      "INFO:root:Epoch 0086, Learning rate: 0.000000, Training loss: 1.46695, Val loss: 0.04187, Test loss: 0.04186, Epoch time: 0.13102\n",
      "INFO:root:Epoch 0087, Learning rate: 0.000000, Training loss: 1.46694, Val loss: 0.04187, Test loss: 0.04186, Epoch time: 0.12761\n",
      "INFO:root:Epoch 0088, Learning rate: 0.000000, Training loss: 1.46695, Val loss: 0.04186, Test loss: 0.04186, Epoch time: 0.12816\n",
      "INFO:root:Epoch 0089, Learning rate: 0.000000, Training loss: 1.46698, Val loss: 0.04187, Test loss: 0.04186, Epoch time: 0.12976\n",
      "INFO:root:Epoch 0090, Learning rate: 0.000000, Training loss: 1.46698, Val loss: 0.04188, Test loss: 0.04189, Epoch time: 0.13257\n",
      "INFO:root:Epoch 0091, Learning rate: 0.000000, Training loss: 1.46695, Val loss: 0.04186, Test loss: 0.04186, Epoch time: 0.19249\n",
      "INFO:root:Epoch 0092, Learning rate: 0.000000, Training loss: 1.46698, Val loss: 0.04187, Test loss: 0.04190, Epoch time: 0.15185\n",
      "INFO:root:Epoch 0093, Learning rate: 0.000000, Training loss: 1.46695, Val loss: 0.04187, Test loss: 0.04190, Epoch time: 0.17396\n",
      "INFO:root:Epoch 0094, Learning rate: 0.000000, Training loss: 1.46695, Val loss: 0.04186, Test loss: 0.04186, Epoch time: 0.16136\n",
      "INFO:root:Epoch 0095, Learning rate: 0.000000, Training loss: 1.46694, Val loss: 0.04187, Test loss: 0.04186, Epoch time: 0.19393\n",
      "INFO:root:Epoch 0096, Learning rate: 0.000000, Training loss: 1.46695, Val loss: 0.04187, Test loss: 0.04187, Epoch time: 0.13997\n",
      "INFO:root:Epoch 0097, Learning rate: 0.000000, Training loss: 1.46697, Val loss: 0.04188, Test loss: 0.04186, Epoch time: 0.13322\n",
      "INFO:root:Epoch 0098, Learning rate: 0.000000, Training loss: 1.46694, Val loss: 0.04185, Test loss: 0.04188, Epoch time: 0.13782\n",
      "INFO:root:Epoch 0099, Learning rate: 0.000000, Training loss: 1.46695, Val loss: 0.04186, Test loss: 0.04188, Epoch time: 0.17822\n",
      "INFO:root:Epoch 0100, Learning rate: 0.000000, Training loss: 1.46694, Val loss: 0.04187, Test loss: 0.04193, Epoch time: 0.16058\n",
      "INFO:root:Best model at epoch 0098 with validation loss 0.04185\n"
     ]
    }
   ],
   "source": [
    "trainer.train(**trainer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res = trainer.predict(train_data)\n",
    "test_res = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9944382647385984"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(train_res, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_res, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_toolbox.metrics import precision_recall\n",
    "conf_matrix, precision, recall, f1 = precision_recall(trainer, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5044230769230771"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
