{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset (Or directly load from saved numpy arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zheng\\AppData\\Local\\Temp\\ipykernel_9420\\158973850.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.350088</td>\n",
       "      <td>0.088757</td>\n",
       "      <td>0.130228</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>1784.165850</td>\n",
       "      <td>129774.064525</td>\n",
       "      <td>2002.449060</td>\n",
       "      <td>85882.761315</td>\n",
       "      <td>...</td>\n",
       "      <td>52.420910</td>\n",
       "      <td>-1.690215</td>\n",
       "      <td>36.524071</td>\n",
       "      <td>-0.408979</td>\n",
       "      <td>41.597103</td>\n",
       "      <td>-2.303523</td>\n",
       "      <td>55.062923</td>\n",
       "      <td>1.221291</td>\n",
       "      <td>46.936035</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00001.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.340914</td>\n",
       "      <td>0.094980</td>\n",
       "      <td>0.095948</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>1530.176679</td>\n",
       "      <td>375850.073649</td>\n",
       "      <td>2039.036516</td>\n",
       "      <td>213843.755497</td>\n",
       "      <td>...</td>\n",
       "      <td>55.356403</td>\n",
       "      <td>-0.731125</td>\n",
       "      <td>60.314529</td>\n",
       "      <td>0.295073</td>\n",
       "      <td>48.120598</td>\n",
       "      <td>-0.283518</td>\n",
       "      <td>51.106190</td>\n",
       "      <td>0.531217</td>\n",
       "      <td>45.786282</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00002.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.363637</td>\n",
       "      <td>0.085275</td>\n",
       "      <td>0.175570</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>1552.811865</td>\n",
       "      <td>156467.643368</td>\n",
       "      <td>1747.702312</td>\n",
       "      <td>76254.192257</td>\n",
       "      <td>...</td>\n",
       "      <td>40.598766</td>\n",
       "      <td>-7.729093</td>\n",
       "      <td>47.639427</td>\n",
       "      <td>-1.816407</td>\n",
       "      <td>52.382141</td>\n",
       "      <td>-3.439720</td>\n",
       "      <td>46.639660</td>\n",
       "      <td>-2.231258</td>\n",
       "      <td>30.573025</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.093999</td>\n",
       "      <td>0.141093</td>\n",
       "      <td>0.006346</td>\n",
       "      <td>1070.106615</td>\n",
       "      <td>184355.942417</td>\n",
       "      <td>1596.412872</td>\n",
       "      <td>166441.494769</td>\n",
       "      <td>...</td>\n",
       "      <td>44.427753</td>\n",
       "      <td>-3.319597</td>\n",
       "      <td>50.206673</td>\n",
       "      <td>0.636965</td>\n",
       "      <td>37.319130</td>\n",
       "      <td>-0.619121</td>\n",
       "      <td>37.259739</td>\n",
       "      <td>-3.407448</td>\n",
       "      <td>31.949339</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00004.wav</td>\n",
       "      <td>661794</td>\n",
       "      <td>0.308526</td>\n",
       "      <td>0.087841</td>\n",
       "      <td>0.091529</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>1835.004266</td>\n",
       "      <td>343399.939274</td>\n",
       "      <td>1748.172116</td>\n",
       "      <td>88445.209036</td>\n",
       "      <td>...</td>\n",
       "      <td>86.099236</td>\n",
       "      <td>-5.454034</td>\n",
       "      <td>75.269707</td>\n",
       "      <td>-0.916874</td>\n",
       "      <td>53.613918</td>\n",
       "      <td>-4.404827</td>\n",
       "      <td>62.910812</td>\n",
       "      <td>-11.703234</td>\n",
       "      <td>55.195160</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename  length  chroma_stft_mean  chroma_stft_var  rms_mean  \\\n",
       "0  blues.00000.wav  661794          0.350088         0.088757  0.130228   \n",
       "1  blues.00001.wav  661794          0.340914         0.094980  0.095948   \n",
       "2  blues.00002.wav  661794          0.363637         0.085275  0.175570   \n",
       "3  blues.00003.wav  661794          0.404785         0.093999  0.141093   \n",
       "4  blues.00004.wav  661794          0.308526         0.087841  0.091529   \n",
       "\n",
       "    rms_var  spectral_centroid_mean  spectral_centroid_var  \\\n",
       "0  0.002827             1784.165850          129774.064525   \n",
       "1  0.002373             1530.176679          375850.073649   \n",
       "2  0.002746             1552.811865          156467.643368   \n",
       "3  0.006346             1070.106615          184355.942417   \n",
       "4  0.002303             1835.004266          343399.939274   \n",
       "\n",
       "   spectral_bandwidth_mean  spectral_bandwidth_var  ...  mfcc16_var  \\\n",
       "0              2002.449060            85882.761315  ...   52.420910   \n",
       "1              2039.036516           213843.755497  ...   55.356403   \n",
       "2              1747.702312            76254.192257  ...   40.598766   \n",
       "3              1596.412872           166441.494769  ...   44.427753   \n",
       "4              1748.172116            88445.209036  ...   86.099236   \n",
       "\n",
       "   mfcc17_mean  mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  \\\n",
       "0    -1.690215   36.524071    -0.408979   41.597103    -2.303523   55.062923   \n",
       "1    -0.731125   60.314529     0.295073   48.120598    -0.283518   51.106190   \n",
       "2    -7.729093   47.639427    -1.816407   52.382141    -3.439720   46.639660   \n",
       "3    -3.319597   50.206673     0.636965   37.319130    -0.619121   37.259739   \n",
       "4    -5.454034   75.269707    -0.916874   53.613918    -4.404827   62.910812   \n",
       "\n",
       "   mfcc20_mean  mfcc20_var  label  \n",
       "0     1.221291   46.936035  blues  \n",
       "1     0.531217   45.786282  blues  \n",
       "2    -2.231258   30.573025  blues  \n",
       "3    -3.407448   31.949339  blues  \n",
       "4   -11.703234   55.195160  blues  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "audio_root_folder = './archive/data'\n",
    "labels_csv = os.path.join(audio_root_folder, 'features_30_sec.csv')\n",
    "df = pd.read_csv(labels_csv, header=0)\n",
    "df.drop(df.loc[df.filename == 'jazz.00054.wav'].index, inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "RANDOM_SEED = RANDOM_STATE = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.random.manual_seed(RANDOM_SEED);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "filenames = df['filename']\n",
    "labels = df['label']\n",
    "\n",
    "files_train, files_test, labels_train, labels_test = train_test_split(\n",
    "    filenames, labels, test_size=0.1, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading audios for Training set: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 899/899 [00:06<00:00, 129.31it/s]\n",
      "Processing for Training set: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 899/899 [03:09<00:00,  4.73it/s]\n",
      "Loading audios for Testing set: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 146.75it/s]\n",
      "Processing for Testing set: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:15<00:00,  6.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from audio_toolbox.dataset import AudioOTFDataset\n",
    "\n",
    "num_frames = 1290\n",
    "label_encoding = 'Label'\n",
    "scaling_strategy = None\n",
    "\n",
    "datasets = {\n",
    "    'train':\n",
    "        AudioOTFDataset(\n",
    "            root_folder=audio_root_folder,\n",
    "            filenames=files_train.tolist(),\n",
    "            labels=labels_train.tolist(),\n",
    "            num_frames=num_frames,\n",
    "            scaling_strategy=scaling_strategy,\n",
    "            name='Training set',\n",
    "            label_encoding=label_encoding\n",
    "        ),\n",
    "    'test':\n",
    "        AudioOTFDataset(\n",
    "            root_folder=audio_root_folder,\n",
    "            filenames=files_test.tolist(),\n",
    "            labels=labels_test.tolist(),\n",
    "            num_frames=num_frames,\n",
    "            scaling_strategy=scaling_strategy,\n",
    "            name='Testing set',\n",
    "            label_encoding=label_encoding\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(899, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train, n_test = len(datasets['train']), len(datasets['test'])\n",
    "n_train, n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Training set ======\n",
      "Root folder: ./archive/data\n",
      "Number of samples: 899\n",
      "Shape of one sample: torch.Size([72, 1290])\n",
      "Number of classes: 10\n",
      "Features:\n",
      "\tn_mfcc: 12\n",
      "\tn_chroma: 12\n",
      "\tn_derivatives: 2\n",
      "Scaling strategy: None\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "print(repr(datasets['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Testing set ======\n",
      "Root folder: ./archive/data\n",
      "Number of samples: 100\n",
      "Shape of one sample: torch.Size([72, 1290])\n",
      "Number of classes: 10\n",
      "Features:\n",
      "\tn_mfcc: 12\n",
      "\tn_chroma: 12\n",
      "\tn_derivatives: 2\n",
      "Scaling strategy: None\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "print(repr(datasets['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((899, 72, 1290), (100, 72, 1290))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.stack([datasets['train'][i][0] for i in range(len(datasets['train']))]).cpu().numpy()\n",
    "X_test = torch.stack([datasets['test'][i][0] for i in range(len(datasets['test']))]).cpu().numpy()\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((899,), (100,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = datasets['train'].labels.cpu().numpy()\n",
    "y_test = datasets['test'].labels.cpu().numpy()\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flat = X_train.reshape((X_train.shape[0], -1))\n",
    "# y_train_labels = np.argmax(y_train, axis=1)\n",
    "\n",
    "X_test_flat = X_test.reshape((X_test.shape[0], -1))\n",
    "# y_test_labels = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened training samples and labels: (899, 92880) (899,)\n",
      "Flattened test samples and labels: (100, 92880) (100,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Flattened training samples and labels:\", X_train_flat.shape, y_train.shape)\n",
    "print(\"Flattened test samples and labels:\", X_test_flat.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data saved\n",
      "Train label saved\n",
      "Test data saved\n",
      "Test label saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Save the processed arrays to save time\n",
    "os.makedirs('./processed_data/ml_data', exist_ok=True)\n",
    "np.save('processed_data/ml_modeling_train_data.npy', X_train_flat)\n",
    "print('Train data saved')\n",
    "np.save('processed_data/ml_modeling_train_label.npy', y_train)\n",
    "print('Train label saved')\n",
    "np.save('processed_data/ml_modeling_test_data.npy', X_test_flat)\n",
    "print('Test data saved')\n",
    "np.save('processed_data/ml_modeling_test_label.npy', y_test)\n",
    "print('Test label saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directly load saved numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened training samples and labels: (899, 92880) (899,)\n",
      "Flattened test samples and labels: (100, 92880) (100,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train_flat = np.load('processed_data/ml_modeling_train_data.npy')\n",
    "X_test_flat = np.load('processed_data/ml_modeling_test_data.npy')\n",
    "y_train = np.load('processed_data/ml_modeling_train_label.npy')\n",
    "y_test = np.load('processed_data/ml_modeling_test_label.npy')\n",
    "\n",
    "print(\"Flattened training samples and labels:\", X_train_flat.shape, y_train.shape)\n",
    "print(\"Flattened test samples and labels:\", X_test_flat.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "RANDOM_SEED = RANDOM_STATE = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.random.manual_seed(RANDOM_SEED);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do PCA on flattened features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler and PCA\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=0.9)  # Keep 90% of the variance\n",
    "\n",
    "# Fit the scaler on the training set and transform all sets\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "X_test_scaled = scaler.transform(X_test_flat)\n",
    "\n",
    "reduced_X_train_flat = pca.fit_transform(X_train_scaled)\n",
    "reduced_X_test_flat = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: (899, 92880) -> (899, 662)\n",
      "Test samples: (100, 92880) -> (100, 662)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training samples: {X_train_flat.shape} -> {reduced_X_train_flat.shape}\")\n",
    "print(f\"Test samples: {X_test_flat.shape} -> {reduced_X_test_flat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitting finished\n",
      "Train accuracy: 99.8888%, 1 mismatches out of 899 samples\n",
      "(Averaged) Train precision: 0.9989, recall: 0.9989, f1 score: 0.9989\n",
      "Test accuracy: 52.0000%, 48 mismatches out of 100 samples\n",
      "(Averaged) Test precision: 0.5200, recall: 0.5295, f1 score: 0.4889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from audio_toolbox.metrics import calculate_acc, precision_recall\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=1000, C=1e-3, random_state=RANDOM_STATE)\n",
    "logistic_model.fit(reduced_X_train_flat, y_train)\n",
    "print('Model fitting finished')\n",
    "\n",
    "for x, y, split in zip([reduced_X_train_flat, reduced_X_test_flat],\n",
    "                [y_train, y_test],\n",
    "                ['Train', 'Test']):\n",
    "    acc, correct, incorrect = calculate_acc(logistic_model, x, y)\n",
    "    print(f'{split} accuracy: {acc:.4f}%, {len(incorrect)} mismatches out of {len(incorrect) + len(correct)} samples')\n",
    "    conf_mat, precision, recall, f1 = precision_recall(logistic_model, x, y, return_each_class=False)\n",
    "    print(f'(Averaged) {split} precision: {precision:.4f}, recall: {recall:.4f}, f1 score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitting finished\n",
      "Train accuracy: 10.5673%, 804 mismatches out of 899 samples\n",
      "(Averaged) Train precision: 0.1057, recall: 0.1000, f1 score: 0.0191\n",
      "Test accuracy: 5.0000%, 95 mismatches out of 100 samples\n",
      "(Averaged) Test precision: 0.0500, recall: 0.1000, f1 score: 0.0095\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_classifier = SVC(C=1e-3, random_state=RANDOM_STATE)\n",
    "svm_classifier.fit(reduced_X_train_flat, y_train)\n",
    "\n",
    "print('Model fitting finished')\n",
    "\n",
    "for x, y, split in zip([reduced_X_train_flat, reduced_X_test_flat],\n",
    "                [y_train, y_test],\n",
    "                ['Train', 'Test']):\n",
    "    acc, correct, incorrect = calculate_acc(svm_classifier, x, y)\n",
    "    print(f'{split} accuracy: {acc:.4f}%, {len(incorrect)} mismatches out of {len(incorrect) + len(correct)} samples')\n",
    "    conf_mat, precision, recall, f1 = precision_recall(svm_classifier, x, y, return_each_class=False)\n",
    "    print(f'(Averaged) {split} precision: {precision:.4f}, recall: {recall:.4f}, f1 score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitting finished\n",
      "Train accuracy: 98.5539%, 13 mismatches out of 899 samples\n",
      "(Averaged) Train precision: 0.9861, recall: 0.9850, f1 score: 0.9854\n",
      "Test accuracy: 32.0000%, 68 mismatches out of 100 samples\n",
      "(Averaged) Test precision: 0.4814, recall: 0.3291, f1 score: 0.2068\n"
     ]
    }
   ],
   "source": [
    "ovo_svm = SVC(decision_function_shape='ovo', random_state=RANDOM_STATE)\n",
    "ovo_svm.fit(reduced_X_train_flat, y_train)\n",
    "\n",
    "print('Model fitting finished')\n",
    "\n",
    "for x, y, split in zip([reduced_X_train_flat, reduced_X_test_flat],\n",
    "                [y_train, y_test],\n",
    "                ['Train', 'Test']):\n",
    "    acc, correct, incorrect = calculate_acc(ovo_svm, x, y)\n",
    "    print(f'{split} accuracy: {acc:.4f}%, {len(incorrect)} mismatches out of {len(incorrect) + len(correct)} samples')\n",
    "    conf_mat, precision, recall, f1 = precision_recall(ovo_svm, x, y, return_each_class=False)\n",
    "    print(f'(Averaged) {split} precision: {precision:.4f}, recall: {recall:.4f}, f1 score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitting finished\n",
      "Train accuracy: 82.4249%, 158 mismatches out of 899 samples\n",
      "(Averaged) Train precision: 0.8579, recall: 0.8213, f1 score: 0.8194\n",
      "Test accuracy: 25.0000%, 75 mismatches out of 100 samples\n",
      "(Averaged) Test precision: 0.4264, recall: 0.2888, f1 score: 0.1812\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rand_forest_classifier = RandomForestClassifier(n_estimators=100,\n",
    "                                                max_depth=4,\n",
    "                                                random_state=RANDOM_STATE)\n",
    "rand_forest_classifier.fit(reduced_X_train_flat, y_train)\n",
    "\n",
    "print('Model fitting finished')\n",
    "\n",
    "for x, y, split in zip([reduced_X_train_flat, reduced_X_test_flat],\n",
    "                [y_train, y_test],\n",
    "                ['Train', 'Test']):\n",
    "    acc, correct, incorrect = calculate_acc(rand_forest_classifier, x, y)\n",
    "    print(f'{split} accuracy: {acc:.4f}%, {len(incorrect)} mismatches out of {len(incorrect) + len(correct)} samples')\n",
    "    conf_mat, precision, recall, f1 = precision_recall(rand_forest_classifier, x, y, return_each_class=False)\n",
    "    print(f'(Averaged) {split} precision: {precision:.4f}, recall: {recall:.4f}, f1 score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitting finished\n",
      "Train accuracy: 84.0934%, 143 mismatches out of 899 samples\n",
      "(Averaged) Train precision: 0.8586, recall: 0.8423, f1 score: 0.8411\n",
      "Test accuracy: 55.0000%, 45 mismatches out of 100 samples\n",
      "(Averaged) Test precision: 0.4985, recall: 0.5341, f1 score: 0.4992\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb_classifier = GaussianNB()\n",
    "gnb_classifier.fit(X_train_flat, y_train)\n",
    "\n",
    "print('Model fitting finished')\n",
    "\n",
    "for x, y, split in zip([X_train_flat, X_test_flat],\n",
    "                [y_train, y_test],\n",
    "                ['Train', 'Test']):\n",
    "    acc, correct, incorrect = calculate_acc(gnb_classifier, x, y)\n",
    "    print(f'{split} accuracy: {acc:.4f}%, {len(incorrect)} mismatches out of {len(incorrect) + len(correct)} samples')\n",
    "    conf_mat, precision, recall, f1 = precision_recall(gnb_classifier, x, y, return_each_class=False)\n",
    "    print(f'(Averaged) {split} precision: {precision:.4f}, recall: {recall:.4f}, f1 score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitting finished\n",
      "Train accuracy: 58.2870%, 375 mismatches out of 899 samples\n",
      "(Averaged) Train precision: 0.6660, recall: 0.5773, f1 score: 0.5611\n",
      "Test accuracy: 9.0000%, 91 mismatches out of 100 samples\n",
      "(Averaged) Test precision: 0.4126, recall: 0.1237, f1 score: 0.0539\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb_classifier = GaussianNB()\n",
    "gnb_classifier.fit(reduced_X_train_flat, y_train)\n",
    "\n",
    "print('Model fitting finished')\n",
    "\n",
    "for x, y, split in zip([reduced_X_train_flat, reduced_X_test_flat],\n",
    "                [y_train, y_test],\n",
    "                ['Train', 'Test']):\n",
    "    acc, correct, incorrect = calculate_acc(gnb_classifier, x, y)\n",
    "    print(f'{split} accuracy: {acc:.4f}%, {len(incorrect)} mismatches out of {len(incorrect) + len(correct)} samples')\n",
    "    conf_mat, precision, recall, f1 = precision_recall(gnb_classifier, x, y, return_each_class=False)\n",
    "    print(f'(Averaged) {split} precision: {precision:.4f}, recall: {recall:.4f}, f1 score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitting finished\n",
      "Train accuracy: 99.6663%, 3 mismatches out of 899 samples\n",
      "(Averaged) Train precision: 0.6660, recall: 0.5773, f1 score: 0.5611\n",
      "Test accuracy: 44.0000%, 56 mismatches out of 100 samples\n",
      "(Averaged) Test precision: 0.4126, recall: 0.1237, f1 score: 0.0539\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "xgboost_classifier = GradientBoostingClassifier(subsample=0.8, max_depth=2, random_state=RANDOM_STATE)\n",
    "xgboost_classifier.fit(reduced_X_train_flat, y_train)\n",
    "\n",
    "print('Model fitting finished')\n",
    "\n",
    "for x, y, split in zip([reduced_X_train_flat, reduced_X_test_flat],\n",
    "                [y_train, y_test],\n",
    "                ['Train', 'Test']):\n",
    "    acc, correct, incorrect = calculate_acc(xgboost_classifier, x, y)\n",
    "    print(f'{split} accuracy: {acc:.4f}%, {len(incorrect)} mismatches out of {len(incorrect) + len(correct)} samples')\n",
    "    conf_mat, precision, recall, f1 = precision_recall(gnb_classifier, x, y, return_each_class=False)\n",
    "    print(f'(Averaged) {split} precision: {precision:.4f}, recall: {recall:.4f}, f1 score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
